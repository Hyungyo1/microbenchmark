/scale/cal/home-interns/younjoo0614/anaconda3/envs/flexgen/lib/python3.10/site-packages/torch/__init__.py:836: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/scale/cal/home-interns/younjoo0614/nskim/FlexiGen/flexgen/utils.py:132: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  data_ptr = tensor.storage().data_ptr()
<run_flexgen>: args.model: facebook/opt-175b
model size: 325.175 GB, cache size: 2.250 GB, hidden size (prefill): 0.012 GB
init weight...
warmup - generate
benchmark - generate
TorchDevice: cuda:0
  cur_mem: 27.0914 GB,  peak_mem: 32.7900 GB
TorchDevice: cpu
  cur_mem: 299.3167 GB,  peak_mem: 0.0000 GB
model size: 325.175 GB	cache size: 2.250 GB	hidden size (p): 0.012 GB
peak gpu mem: 32.790 GB	projected: False
prefill latency: 12.740 s	prefill throughput: 20.093 token/s
decode latency: 2863.551 s	decode throughput: 0.089 token/s
total latency: 2876.292 s	total throughput: 0.089 token/s
